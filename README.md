

Paper Information

Title: **Multimodal Movie Recommendation with Multitasking Architecture and Learning User-Movie Representation: An Empirical Study**

Accepted at: TCSS Journal

Authors: Subham Raj, Sriparna Saha, Brijraj Singh, Niranjan Pedanekar

Contact for Source Data:Subham RajEmail: subham_2221cs25@iitp.ac.in

Abstract

With the increasing availability of multimodal movie data, there is a growing interest in leveraging this data to improve movie recommendations. In the recent era, due to the increase in the number of users and movies on OTT platforms such as Amazon Prime, its services, including personalized movie recommendations, become challenging. This paper proposes a novel approach $M^2RM^2UL$, which stands for Multimodal Movie Recommendation with Multitasking and Movie-User Learning. The initial phase involves preprocessing multimodal movie data to extract features encompassing visual and textual information. Subsequently, a multitasking architecture is employed, simultaneously undertaking classification and regression tasks to acquire user and movie representations. The learned representations are used to make personalized and accurate movie recommendations.

Additionally, the Netflix Prize dataset has been augmented to include textual and visual features, rendering it multimodal. We conducted extensive experiments on three real-world multimodal movie datasets (Movielens-100K, MMTF-14K, and Netflix Prize) and compared our approach with several state-of-the-art movie recommendation algorithms. The experimental results illustrate that our approach outperforms the baseline methods in terms of recommendation accuracy and diversity. Furthermore, we demonstrate the effectiveness of our approach in different scenarios, such as cold-start and sparse data. Our empirical study provides strong evidence for the effectiveness of the proposed approach in multimodal movie recommendation.

